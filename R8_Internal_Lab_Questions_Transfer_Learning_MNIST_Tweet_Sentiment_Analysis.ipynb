{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_Internal_Lab_Questions_Transfer_Learning_MNIST_Tweet_Sentiment_Analysis_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFfDTfhlaEI_"
      },
      "source": [
        "# Transfer Learning MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNwbqCFRaEJC"
      },
      "source": [
        "* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YUB1uDW_8XIy"
      },
      "source": [
        "## 1. Import necessary libraries for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rsj4t5HTaEJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd0ae078-0524-410a-fa86-82f6d1b7137c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import vis\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXrn3heBaEJa"
      },
      "source": [
        "## 2. Import MNIST data and create 2 datasets with one dataset having digits from 0 to 4 and other from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pjDuiK6ztgOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44e06133-57fb-41b9-a4f2-bf6f6f6e8eaf"
      },
      "source": [
        "(trainX, trainY), (testX, testY) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDLDILLDokXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_0_4 = np.isin(trainY, [0,1,2,3,4])\n",
        "test_0_4 = np.isin(testY, [0,1,2,3,4])\n",
        "train_5_9 = np.isin(trainY, [5,6,7,8,9])\n",
        "test_5_9 = np.isin(testY, [5,6,7,8,9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dSOw1Sapudv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split the dataset 0-4 and 5-9\n",
        "\n",
        "X_train04, Y_train04 = trainX[train_0_4], trainY[train_0_4]\n",
        "X_test04, Y_test04 = testX[test_0_4], testY[test_0_4]\n",
        "\n",
        "X_train59, Y_train59 = trainX[train_5_9], trainY[train_5_9]\n",
        "X_test59, Y_test59 = testX[test_5_9], testY[test_5_9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9qU14lYL9A5g"
      },
      "source": [
        "## 3. Print x_train, y_train, x_test and y_test for both the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z9OrszhJ0SgJ",
        "outputId": "478f45eb-6440-439a-98bd-e93a58e8f06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(X_train04)\n",
        "print(X_test04)\n",
        "\n",
        "print(Y_train04)\n",
        "print(Y_test04)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n",
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n",
            "[0 4 1 ... 2 1 3]\n",
            "[2 1 0 ... 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJswV4xk9jQS",
        "outputId": "9e8483b8-f684-47fd-e2ce-a9bb5c3c1d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(X_train59)\n",
        "print(X_test59)\n",
        "\n",
        "print(Y_train59)\n",
        "print(Y_test59)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n",
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n",
            "[5 9 5 ... 5 6 8]\n",
            "[7 9 5 ... 9 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cB9BPFzr9oDF"
      },
      "source": [
        "## ** 4. Let us take only the dataset (x_train, y_train, x_test, y_test) for Integers 0 to 4 in MNIST **\n",
        "## Reshape x_train and x_test to a 4 Dimensional array (channel = 1) to pass it into a Conv2D layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FlQRPfFzaEJx",
        "colab": {}
      },
      "source": [
        "X_train04.shape\n",
        "# Reshape data for convlution netowkr\n",
        "x_train04_conv = X_train04.reshape(X_train04.shape[0], 28, 28, 1)\n",
        "x_test04_conv = X_test04.reshape(X_test04.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jLQr-b3F-hw8"
      },
      "source": [
        "## 5. Normalize x_train and x_test by dividing it by 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PlEZIAG5-g2I",
        "colab": {}
      },
      "source": [
        "\n",
        "# Convert from 'uint8' to 'float32' and normalise the data to (0,1) \n",
        "x_train04_conv =  x_train04_conv.astype(\"float32\") / 255\n",
        "x_test04_conv = x_test04_conv.astype(\"float32\") / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pytVBaw4-vMi"
      },
      "source": [
        "## 6. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V48xiua4-uUi",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train_class = keras.utils.to_categorical(Y_train04, 10)\n",
        "y_test_class = keras.utils.to_categorical(Y_test04, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsWD-Ec61hAE",
        "colab_type": "code",
        "outputId": "e44665bf-4629-457e-fd25-83f4a14da43e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train_class[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "elPkI44g_C2b"
      },
      "source": [
        "## 7. Build a sequential model with 2 Convolutional layers with 32 kernels of size (3,3) followed by a Max pooling layer of size (2,2) followed by a drop out layer to be trained for classification of digits 0-4  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MU09mm9F89gO",
        "colab": {}
      },
      "source": [
        "#Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape,name='conv_1'))\n",
        "\n",
        "#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
        "model.add(Conv2D(32, (3, 3), activation='relu',name='conv_2'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model.add(Dropout(0.25,name='drop_1'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sJQaycRO_3Au"
      },
      "source": [
        "## 8. Post that flatten the data and add 2 Dense layers with 128 neurons and neurons = output classes with activation = 'relu' and 'softmax' respectively. Add dropout layer inbetween if necessary  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vOZeRbK7t9AT",
        "colab": {}
      },
      "source": [
        "#Flatten the layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model.add(Dense(128, activation='relu',name='dense_1'))\n",
        "\n",
        "#Apply Dropout with 0.5 probability \n",
        "model.add(Dropout(0.5,name='drop_2'))\n",
        "\n",
        "#Add Fully Connected Layer with 5 units and activation function as 'softmax'\n",
        "model.add(Dense(10, activation='softmax',name='dense_2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "my1P09bxAv8H"
      },
      "source": [
        "## 9. Print the training and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yf7F8Gdutbf0",
        "outputId": "b508271c-2c7b-41ab-9c80-e164fa910e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "#To use adam optimizer for learning weights with learning rate = 0.001\n",
        "optimizer = Adam(lr=0.001)\n",
        "#Set the loss function and optimizer for the model training\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy']) \n",
        "\n",
        "\n",
        "#Training on the dataset\n",
        "model.fit(x_train04_conv, y_train_class,\n",
        "          batch_size=50,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test04_conv, y_test_class))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30596 samples, validate on 5139 samples\n",
            "Epoch 1/20\n",
            "30596/30596 [==============================] - 7s 222us/step - loss: 0.1085 - acc: 0.9665 - val_loss: 0.0136 - val_acc: 0.9959\n",
            "Epoch 2/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0324 - acc: 0.9900 - val_loss: 0.0090 - val_acc: 0.9961\n",
            "Epoch 3/20\n",
            "30596/30596 [==============================] - 6s 207us/step - loss: 0.0216 - acc: 0.9931 - val_loss: 0.0055 - val_acc: 0.9979\n",
            "Epoch 4/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0059 - val_acc: 0.9981\n",
            "Epoch 5/20\n",
            "30596/30596 [==============================] - 6s 208us/step - loss: 0.0151 - acc: 0.9949 - val_loss: 0.0035 - val_acc: 0.9990\n",
            "Epoch 6/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0057 - val_acc: 0.9981\n",
            "Epoch 7/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.0060 - val_acc: 0.9984\n",
            "Epoch 8/20\n",
            "30596/30596 [==============================] - 6s 208us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0039 - val_acc: 0.9988\n",
            "Epoch 9/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0037 - val_acc: 0.9992\n",
            "Epoch 10/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0072 - val_acc: 0.9977\n",
            "Epoch 11/20\n",
            "30596/30596 [==============================] - 6s 208us/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0055 - val_acc: 0.9982\n",
            "Epoch 12/20\n",
            "30596/30596 [==============================] - 6s 210us/step - loss: 0.0057 - acc: 0.9978 - val_loss: 0.0034 - val_acc: 0.9990\n",
            "Epoch 13/20\n",
            "30596/30596 [==============================] - 6s 210us/step - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0042 - val_acc: 0.9984\n",
            "Epoch 14/20\n",
            "30596/30596 [==============================] - 6s 211us/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0058 - val_acc: 0.9984\n",
            "Epoch 15/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0044 - val_acc: 0.9986\n",
            "Epoch 16/20\n",
            "30596/30596 [==============================] - 6s 210us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0119 - val_acc: 0.9977\n",
            "Epoch 17/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0045 - val_acc: 0.9990\n",
            "Epoch 18/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0043 - val_acc: 0.9981\n",
            "Epoch 19/20\n",
            "30596/30596 [==============================] - 6s 209us/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.0025 - val_acc: 0.9988\n",
            "Epoch 20/20\n",
            "30596/30596 [==============================] - 6s 210us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0045 - val_acc: 0.9986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdb4d9d6cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS4wempqHhYD",
        "colab_type": "code",
        "outputId": "7f1912eb-7bb2-44cf-9b79-4462fb0cf021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Testing the model on test set\n",
        "score = model.evaluate(x_test04_conv, y_test_class)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Test loss: 0.004541439346094206\n",
            "Test accuracy: 0.9986378672893559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z78o3WIjaEJ3"
      },
      "source": [
        "## 10. Make only the dense layers to be trainable and convolutional layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brN7VZHFaEJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7a4de676-b8c4-43ae-b4b6-9f12f58f2f0d"
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "for layer in model.layers:\n",
        "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False\n",
        "\n",
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in model.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mconv_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdrop_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mflatten_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_1\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdrop_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_2\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67YmG8_hfH7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa397280-24b5-4a19-c4af-c8656b745e94"
      },
      "source": [
        "np.unique(Y_train59)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4opnW7o0BJ8P"
      },
      "source": [
        "## 11. Use the model trained on 0 to 4 digit classification and train it on the dataset which has digits 5 to 9  (Using Transfer learning keeping only the dense layers to be trainable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lCFcYHTm6-cE",
        "colab": {}
      },
      "source": [
        "X_train59.shape\n",
        "# Reshape data for convlution netowkr\n",
        "x_train59_conv = X_train59.reshape(X_train59.shape[0], 28, 28, 1)\n",
        "x_test59_conv = X_test59.reshape(X_test59.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Convert from 'uint8' to 'float32' and normalise the data to (0,1) \n",
        "x_train59_conv =  x_train59_conv.astype(\"float32\") / 255\n",
        "x_test59_conv = x_test59_conv.astype(\"float32\") / 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train_class59 = keras.utils.to_categorical(Y_train59, num_classes=10)\n",
        "y_test_class59 = keras.utils.to_categorical(Y_test59, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DITyAt3t7Tto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "663c041a-9e39-433a-ed9a-1dd869e80918"
      },
      "source": [
        "#Training on the dataset\n",
        "model.fit(x_train59_conv, y_train_class59,\n",
        "          batch_size=50,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test59_conv,y_test_class59))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29404 samples, validate on 4861 samples\n",
            "Epoch 1/20\n",
            "  800/29404 [..............................] - ETA: 6s - loss: 6.2113 - acc: 0.0500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "29404/29404 [==============================] - 6s 209us/step - loss: 0.7925 - acc: 0.7203 - val_loss: 0.1222 - val_acc: 0.9615\n",
            "Epoch 2/20\n",
            "29404/29404 [==============================] - 6s 204us/step - loss: 0.3012 - acc: 0.8922 - val_loss: 0.0782 - val_acc: 0.9768\n",
            "Epoch 3/20\n",
            "29404/29404 [==============================] - 6s 206us/step - loss: 0.2153 - acc: 0.9270 - val_loss: 0.0686 - val_acc: 0.9788\n",
            "Epoch 4/20\n",
            "29404/29404 [==============================] - 6s 204us/step - loss: 0.1751 - acc: 0.9418 - val_loss: 0.0573 - val_acc: 0.9823\n",
            "Epoch 5/20\n",
            "29404/29404 [==============================] - 6s 204us/step - loss: 0.1501 - acc: 0.9511 - val_loss: 0.0500 - val_acc: 0.9866\n",
            "Epoch 6/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.1328 - acc: 0.9570 - val_loss: 0.0462 - val_acc: 0.9866\n",
            "Epoch 7/20\n",
            "29404/29404 [==============================] - 6s 204us/step - loss: 0.1193 - acc: 0.9626 - val_loss: 0.0468 - val_acc: 0.9866\n",
            "Epoch 8/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.1133 - acc: 0.9651 - val_loss: 0.0398 - val_acc: 0.9881\n",
            "Epoch 9/20\n",
            "29404/29404 [==============================] - 6s 204us/step - loss: 0.1083 - acc: 0.9677 - val_loss: 0.0377 - val_acc: 0.9883\n",
            "Epoch 10/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0934 - acc: 0.9712 - val_loss: 0.0367 - val_acc: 0.9899\n",
            "Epoch 11/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0836 - acc: 0.9749 - val_loss: 0.0363 - val_acc: 0.9889\n",
            "Epoch 12/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0762 - acc: 0.9771 - val_loss: 0.0303 - val_acc: 0.9918\n",
            "Epoch 13/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0667 - acc: 0.9802 - val_loss: 0.0311 - val_acc: 0.9914\n",
            "Epoch 14/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0609 - acc: 0.9818 - val_loss: 0.0260 - val_acc: 0.9928\n",
            "Epoch 15/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0537 - acc: 0.9839 - val_loss: 0.0265 - val_acc: 0.9924\n",
            "Epoch 16/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0514 - acc: 0.9845 - val_loss: 0.0282 - val_acc: 0.9934\n",
            "Epoch 17/20\n",
            "29404/29404 [==============================] - 6s 202us/step - loss: 0.0504 - acc: 0.9839 - val_loss: 0.0237 - val_acc: 0.9938\n",
            "Epoch 18/20\n",
            "29404/29404 [==============================] - 6s 204us/step - loss: 0.0439 - acc: 0.9862 - val_loss: 0.0265 - val_acc: 0.9938\n",
            "Epoch 19/20\n",
            "29404/29404 [==============================] - 6s 202us/step - loss: 0.0443 - acc: 0.9859 - val_loss: 0.0249 - val_acc: 0.9940\n",
            "Epoch 20/20\n",
            "29404/29404 [==============================] - 6s 203us/step - loss: 0.0388 - acc: 0.9883 - val_loss: 0.0243 - val_acc: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdb4d38f860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SoDozqghCJZ4"
      },
      "source": [
        "## 12. Print the accuracy for classification of digits 5 to 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fCxgb5s49Cj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "773f1db6-3a21-4f59-a9d7-c92a455a028b"
      },
      "source": [
        "score = model.evaluate(x_test59_conv, y_test_class59)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Test loss: 0.024319507127918954\n",
            "Test accuracy: 0.9934169923883974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRWizZIpCUKg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FU-HwvIdH0M-"
      },
      "source": [
        "## Sentiment analysis <br> \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAQDiZHRH0M_"
      },
      "source": [
        "### 13. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3eXGIe-SH0NA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "22e62c8d-64dd-4c50-b920-d59f8e21f65e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CWeWe1eJH0NF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "06a37c96-30e5-4e21-bf69-4b00a459ef31"
      },
      "source": [
        "tweetsDf = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/tweets.csv',encoding = 'ISO-8859-1',keep_default_na=False)\n",
        "tweetsDf.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36u61zG7MOyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f4e5702c-5a74-4846-9ccc-bba6df20d351"
      },
      "source": [
        "tweetsDf.count()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text                                            9093\n",
              "emotion_in_tweet_is_directed_at                       9093\n",
              "is_there_an_emotion_directed_at_a_brand_or_product    9093\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPHxaykIMePH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0e0ee1f6-7346-4a33-dc4a-e4969a4b91ef"
      },
      "source": [
        "tweetsDf.isnull().sum()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text                                            0\n",
              "emotion_in_tweet_is_directed_at                       0\n",
              "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jPJvTjefH0NI"
      },
      "source": [
        "### 14. Preprocess the text and add the preprocessed text in a column with name `text` in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5iec5s9gH0NI",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    try:\n",
        "        return text.encode().decode('ascii')\n",
        "    except Exception as e:\n",
        "        return e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EQSmqA-vH0NT",
        "colab": {}
      },
      "source": [
        "tweetsDf['text'] = [preprocess(text) for text in tweetsDf.tweet_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7kX-WoJDH0NV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f655835f-d8d5-453c-f4e1-294218522a32"
      },
      "source": [
        "tweetsDf.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ...                                               text\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...  .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...  @jessedee Know about @fludapp ? Awesome iPad/i...\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...  @swonderlin Can not wait for #iPad 2 also. The...\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...  @sxsw I hope this year's festival isn't as cra...\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...  @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OGWB3P2WH0NY"
      },
      "source": [
        "### 15. Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bdgA_8N2H0NY",
        "colab": {}
      },
      "source": [
        "tweetEmoDf = tweetsDf[(tweetsDf['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (tweetsDf['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Jlu-reIH0Na",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9428ac53-bf87-4882-b4de-8e0726ea1a09"
      },
      "source": [
        "tweetEmoDf.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ...                                               text\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...  .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...  @jessedee Know about @fludapp ? Awesome iPad/i...\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...  @swonderlin Can not wait for #iPad 2 also. The...\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...  @sxsw I hope this year's festival isn't as cra...\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...  @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SotCRvkDH0Nf"
      },
      "source": [
        "### 16. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
        "\n",
        "#### Use `vect` as the variable name for initialising CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YcbkY4sgH0Ng",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
        "# bag of words tool.  \n",
        "vect = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None,   \\\n",
        "                             max_features = 7500) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyXtZGr-H0Nl",
        "colab": {}
      },
      "source": [
        "tweetEmoCVDf = vect.fit_transform(tweetEmoDf['tweet_text']).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z4LUM-XPH0Nn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1252c218-889d-4c6e-c5cb-7eaaf0136ae0"
      },
      "source": [
        "tweetEmoCVDf.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3548, 6022)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aIdZYxJtH0Nq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "474e6078-0669-4af9-9663-7d182abf27e9"
      },
      "source": [
        "print(tweetEmoCVDf)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5pxd5fSHH0Nt"
      },
      "source": [
        "### 17. Find number of different words in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p1DQ2LdNH0Nu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ed8e795-f55f-4a8b-dfaf-d9be31b675b0"
      },
      "source": [
        "vocab = vect.get_feature_names()\n",
        "print(len(vocab))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dwtgjTBeH0Ny"
      },
      "source": [
        "#### Tip: To see all available functions for an Object use dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ShA6D8jKH0N5"
      },
      "source": [
        "### 18. Find out how many Positive and Negative emotions are there.\n",
        "\n",
        "Hint: Use value_counts on that column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7LAl5pzH0N6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "72d738e4-7802-47e6-92d0-6827fabf9ade"
      },
      "source": [
        "tweetEmoDf['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion    2978\n",
              "Negative emotion     570\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IUvgj0FoH0N9"
      },
      "source": [
        "### 19. Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'Label'\n",
        "\n",
        "Hint: use map on that column and give labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YftKwFv7H0N9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9418f730-f49e-4f86-bb19-0647c28ed739"
      },
      "source": [
        "emotions = {'Positive emotion' : 1,\n",
        "                'Negative emotion' : 0 }\n",
        "\n",
        "tweetEmoDf['Label'] = tweetEmoDf['is_there_an_emotion_directed_at_a_brand_or_product'].map(emotions)\n",
        "\n",
        "tweetEmoDf.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... Label\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...     0\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...     1\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...     1\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...     0\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### 20. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNkwrGgEH0OA",
        "colab": {}
      },
      "source": [
        "X = tweetEmoCVDf\n",
        "y = tweetEmoDf['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5WaozRGePT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q5nlCuaaH0OD"
      },
      "source": [
        "## 21. **Predicting the sentiment:**\n",
        "\n",
        "\n",
        "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AbVYssaH0OE",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktXrLhmOH0Of",
        "colab": {}
      },
      "source": [
        "model_NB = GaussianNB().fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clv2X0kKH0Ok",
        "colab": {}
      },
      "source": [
        "model_LR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K86LRMfdH0Ou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1725e50b-e41d-498c-b013-e2dafd3646ba"
      },
      "source": [
        "model_NB.score(X_test, y_test)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7718309859154929"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJHxCcGSetOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd05bf1e-989b-438a-8f45-ab7e2b310d8f"
      },
      "source": [
        "model_LR.score(X_test, y_test)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8873239436619719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sw-0B33tH0Ox"
      },
      "source": [
        "## 22. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "okCTOs1TH0Oy",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "Xf = tweetEmoDf['tweet_text']\n",
        "yf = tweetEmoDf['Label']\n",
        "\n",
        "Xf_train, Xf_test, yf_train, yf_test = train_test_split(Xf, yf, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63H3Q_TfdTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_predict(vect):\n",
        "    X_train_dtm = vect.fit_transform(Xf_train)\n",
        "    print('Features: ', X_train_dtm.shape[1])\n",
        "    X_test_dtm = vect.transform(Xf_test)\n",
        "    nb = MultinomialNB()\n",
        "    nb.fit(X_train_dtm, yf_train)\n",
        "    y_pred_class = nb.predict(X_test_dtm)\n",
        "    print('Accuracy: ', metrics.accuracy_score(yf_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wy_T3ndfeuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JxZ8jfPEH0O0"
      },
      "source": [
        "### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kdCyAN_IH0O0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4924fb2a-dcd0-442c-87ef-2ade5b81a44b"
      },
      "source": [
        "vect1 = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None,   \\\n",
        "                             ngram_range = (1,2), \\\n",
        "                             max_features = 7500) \n",
        "\n",
        "tokenize_predict(vect1)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  7500\n",
            "Accuracy:  0.8619718309859155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "axepytmgH0O4"
      },
      "source": [
        "### Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HToGkq7vH0O4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ee785c33-0ed4-4518-f09c-482662145286"
      },
      "source": [
        "vect2 = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = 'english',   \\\n",
        "                             ngram_range = (1,2), \\\n",
        "                             max_features = 7500) \n",
        "\n",
        "tokenize_predict(vect2)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  7500\n",
            "Accuracy:  0.8718309859154929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iOIlJRxoH0O7"
      },
      "source": [
        "### Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6fUhff-oH0O8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3afa7813-8b5a-48e4-8e33-b33154057087"
      },
      "source": [
        "vect3 = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = 'english',   \\\n",
        "                             ngram_range = (1,2), \\\n",
        "                             max_features = 300) \n",
        "tokenize_predict(vect3)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  300\n",
            "Accuracy:  0.7830985915492957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S2KZNWVkH0PA"
      },
      "source": [
        "### Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3v9XD082H0PB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9f57b24-7cc3-4144-9aee-e47aab22eabe"
      },
      "source": [
        "vect4 = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = 'english',   \\\n",
        "                             ngram_range = (1,2), \\\n",
        "                             max_features = 15000) \n",
        "tokenize_predict(vect4)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  15000\n",
            "Accuracy:  0.8704225352112676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "We3JK_SRH0PO"
      },
      "source": [
        "### Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fUHrfDCyH0PP",
        "colab": {}
      },
      "source": [
        "vect5 = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = 'english',   \\\n",
        "                             ngram_range = (1,2), \\\n",
        "                             min_df = 2, \\\n",
        "                             max_features = 15000) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3H4k_lVZH0PS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fdb5bc21-9d7f-4b98-e977-3ad4dae98400"
      },
      "source": [
        "tokenize_predict(vect5)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  6491\n",
            "Accuracy:  0.8704225352112676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWR9spuwhcED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}