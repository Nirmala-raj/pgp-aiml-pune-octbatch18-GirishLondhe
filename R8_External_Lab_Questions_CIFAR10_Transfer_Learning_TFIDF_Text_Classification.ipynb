{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_External_Lab_Questions_CIFAR10_Transfer_Learning_TFIDF_Text_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGIsF1ADyJ58",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-n6tVFayGBe",
        "colab_type": "text"
      },
      "source": [
        "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq8ejXHJyGYq",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWYbxnBayFUP",
        "colab_type": "code",
        "outputId": "8930b950-c851-41c1-faf1-d55f9481e573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import vis\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout\n",
        "from keras import backend as K\n",
        "\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BlKTzsIdzt3",
        "colab_type": "code",
        "outputId": "5d8378ee-1269-4408-e166-8eb663944789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(trainX, trainY),(testX, testY) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNGDq3-xlYJI",
        "colab_type": "code",
        "outputId": "a7884a7a-f60e-4ee4-d724-c39ec713bd59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "print(trainY.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SW8qv89jT-7X",
        "colab": {}
      },
      "source": [
        "trainY = trainY.reshape(50000)\n",
        "testY = testY.reshape(10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8M9O7YAFOfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_lt5 = trainX[trainY < 5]\n",
        "trainY_lt5 = trainY[trainY < 5]\n",
        "testX_lt5 = testX[testY < 5]\n",
        "testY_lt5 = testY[testY < 5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQf-0geORgxk",
        "colab_type": "code",
        "outputId": "b16d45b5-229f-4a88-8b11-9faad63c6bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(trainX_lt5.shape)\n",
        "print(testX_lt5.shape)\n",
        "print(trainY_lt5.shape)\n",
        "print(testY_lt5.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(25000,)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtCKmQh4yXhT",
        "colab_type": "text"
      },
      "source": [
        "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUWhH2ADiJqc",
        "colab_type": "text"
      },
      "source": [
        "*We will only start work with the 0-4 Category Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN5O2kJ3yYa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_lt5_conv = trainX_lt5.reshape(trainX_lt5.shape[0], 32, 32, 3)\n",
        "testX_lt5_conv = testX_lt5.reshape(testX_lt5.shape[0], 32, 32, 3)\n",
        "input_shape = (32, 32, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1nFHwNSUSFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_lt5_conv =  trainX_lt5_conv.astype(\"float32\") / 255\n",
        "testX_lt5_conv = testX_lt5_conv.astype(\"float32\") / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMWjWXEhUbyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY_lt5_class = keras.utils.to_categorical(trainY_lt5, 5)\n",
        "testY_lt5_class = keras.utils.to_categorical(testY_lt5, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOiKWfeybAl",
        "colab_type": "text"
      },
      "source": [
        "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HzxNbiiyoBD",
        "colab_type": "code",
        "outputId": "affbf1e5-b1ed-407d-be30-1d3c2a32a298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model_lt5 = Sequential()\n",
        "model_lt5.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape,name='conv_1'))\n",
        "model_lt5.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "model_lt5.add(Conv2D(128, (3, 3), activation='relu',name='conv_2'))\n",
        "model_lt5.add(MaxPooling2D(pool_size=(2, 2),name='max_2'))\n",
        "model_lt5.add(Conv2D(128, (3, 3), activation='relu',name='conv_3'))\n",
        "model_lt5.add(MaxPooling2D(pool_size=(2, 2),name='max_3'))\n",
        "model_lt5.add(Dropout(0.25,name='drop_1'))\n",
        "model_lt5.add(Flatten())\n",
        "model_lt5.add(Dense(128, activation='relu',name='dense_1'))\n",
        "model_lt5.add(Dropout(0.5, name='drop_2'))\n",
        "model_lt5.add(Dense(5, activation='softmax',name='dense_2'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0627 15:59:27.307792 140187518351232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0627 15:59:27.311166 140187518351232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0627 15:59:27.321634 140187518351232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0627 15:59:27.360873 140187518351232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0627 15:59:27.394671 140187518351232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0627 15:59:27.406294 140187518351232 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snbA59WQU2HR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7abaf8df-e7b7-4457-ade2-baaddc325347"
      },
      "source": [
        "model_lt5.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0627 15:59:27.488720 140187518351232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0627 15:59:27.519162 140187518351232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRHaQQEEVFA7",
        "colab_type": "code",
        "outputId": "06fbe1da-f576-4b65-8e2b-bd139c9d5a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "%%time \n",
        "output_04 = model_lt5.fit(trainX_lt5_conv, trainY_lt5_class, batch_size=50, epochs=10, verbose=1,\n",
        "                    validation_data=(testX_lt5_conv, testY_lt5_class))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "\r   50/25000 [..............................] - ETA: 1:12 - loss: 3.5680 - acc: 0.1000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 57s 2ms/step - loss: 1.6204 - acc: 0.2017 - val_loss: 1.6098 - val_acc: 0.2002\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 58s 2ms/step - loss: 1.6050 - acc: 0.2043 - val_loss: 1.4690 - val_acc: 0.3638\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 57s 2ms/step - loss: 1.1863 - acc: 0.4964 - val_loss: 0.8629 - val_acc: 0.6428\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 56s 2ms/step - loss: 0.8034 - acc: 0.6938 - val_loss: 0.6643 - val_acc: 0.7458\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 56s 2ms/step - loss: 0.6880 - acc: 0.7424 - val_loss: 0.6657 - val_acc: 0.7494\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 58s 2ms/step - loss: 0.6254 - acc: 0.7683 - val_loss: 0.5806 - val_acc: 0.7822\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 58s 2ms/step - loss: 0.5697 - acc: 0.7882 - val_loss: 0.5567 - val_acc: 0.7976\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 58s 2ms/step - loss: 0.5262 - acc: 0.8040 - val_loss: 0.5382 - val_acc: 0.8014\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 57s 2ms/step - loss: 0.4894 - acc: 0.8178 - val_loss: 0.5464 - val_acc: 0.7986\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 57s 2ms/step - loss: 0.4672 - acc: 0.8302 - val_loss: 0.5607 - val_acc: 0.7916\n",
            "CPU times: user 17min, sys: 38.7 s, total: 17min 38s\n",
            "Wall time: 9min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woTfNst_ynRG",
        "colab_type": "text"
      },
      "source": [
        "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_VCDB3Byb1a",
        "colab_type": "code",
        "outputId": "0608d918-fd9d-4e92-a397-f77be31a8bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "for layer in model_lt5.layers:\n",
        "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False\n",
        "\n",
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in model_lt5.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mconv_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv_3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdrop_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mflatten_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_1\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdrop_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_2\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-uUPqWpyeyX",
        "colab_type": "text"
      },
      "source": [
        "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
        "Achieve an accuracy of more than 85% on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szHjJgDvyfCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_gt5 = trainX[trainY >= 5]\n",
        "trainY_gt5 = trainY[trainY >= 5] - 5\n",
        "testX_gt5 = testX[testY >= 5]\n",
        "testY_gt5 = testY[testY >= 5] - 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyxIklfF3E_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_gt5_conv = trainX_gt5.reshape(trainX_gt5.shape[0], 32, 32, 3)\n",
        "testX_gt5_conv = testX_gt5.reshape(testX_gt5.shape[0], 32, 32, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGwdAPiU3QpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_gt5_conv =  trainX_gt5_conv.astype(\"float32\") / 255\n",
        "testX_gt5_conv = testX_gt5_conv.astype(\"float32\") / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTHOUtsu3Zh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY_gt5_class = keras.utils.to_categorical(trainY_gt5, 5)\n",
        "testY_gt5_class = keras.utils.to_categorical(testY_gt5, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTLB_br13gfe",
        "colab_type": "code",
        "outputId": "dd71b520-6365-4dd2-b726-3bff3927ed35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "%%time \n",
        "output_05 = model_lt5.fit(trainX_gt5_conv, trainY_gt5_class, batch_size=100, epochs=5, verbose=1,\n",
        "                    validation_data=(testX_gt5_conv, testY_gt5_class))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.4295 - acc: 0.8468 - val_loss: 0.4296 - val_acc: 0.8466\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.4052 - acc: 0.8537 - val_loss: 0.3994 - val_acc: 0.8538\n",
            "Epoch 3/5\n",
            "25000/25000 [==============================] - 53s 2ms/step - loss: 0.3875 - acc: 0.8622 - val_loss: 0.3781 - val_acc: 0.8664\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 53s 2ms/step - loss: 0.3687 - acc: 0.8674 - val_loss: 0.3746 - val_acc: 0.8644\n",
            "Epoch 5/5\n",
            "25000/25000 [==============================] - 53s 2ms/step - loss: 0.3542 - acc: 0.8731 - val_loss: 0.4139 - val_acc: 0.8500\n",
            "CPU times: user 8min 8s, sys: 10.9 s, total: 8min 19s\n",
            "Wall time: 4min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zDuRecXzEtr",
        "colab_type": "text"
      },
      "source": [
        "# Text classification using TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMPlEJhHzb6P",
        "colab_type": "text"
      },
      "source": [
        "### 6. Load the dataset from sklearn.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe-B59u3zHNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRrMemVQzbHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sZX0UbJzmg5",
        "colab_type": "text"
      },
      "source": [
        "### 7. Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CITr_5aXziJ2",
        "colab_type": "code",
        "outputId": "8c003c70-d946-49a7-a23f-cf6295a21ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "I0627 16:08:05.814660 140187518351232 twenty_newsgroups.py:247] Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
            "I0627 16:08:05.824238 140187518351232 twenty_newsgroups.py:80] Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcESc5QXzr6p",
        "colab_type": "text"
      },
      "source": [
        "### 8. Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysInblUMzpvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DriL2yZ50DQq",
        "colab_type": "text"
      },
      "source": [
        "###  a.  You can access the values for the target variable using .target attribute \n",
        "###  b. You can access the name of the class in the target variable with .target_names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlUuai99z1hX",
        "colab_type": "code",
        "outputId": "6ecbc004-9ee3-4e2a-9da0-aeda7d3174ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twenty_train.target"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEKzaDfSz5E-",
        "colab_type": "code",
        "outputId": "660221ea-f787-4ab6-cefd-c108a8b37b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clBMKHzC0_N1",
        "colab_type": "code",
        "outputId": "fe0ece85-1a6a-4c75-842c-fa3a01f6e37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "twenty_train.data[0:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n',\n",
              " \"From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can help me solve.\\n\\n\\tBackground of the problem:\\n\\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \\n\\tmapping of a 3d Bezier patch into 2d. The area in this domain\\n\\twhich is inside a trimming loop had to be rendered. The trimming\\n\\tloop is a set of 2d Bezier curve segments.\\n\\tFor the sake of notation: the mesh is made up of cells.\\n\\n\\tMy problem is this :\\n\\tThe trimming area has to be split up into individual smaller\\n\\tcells bounded by the trimming curve segments. If a cell\\n\\tis wholly inside the area...then it is output as a whole ,\\n\\telse it is trivially rejected. \\n\\n\\tDoes any body know how thiss can be done, or is there any algo. \\n\\tsomewhere for doing this.\\n\\n\\tAny help would be appreciated.\\n\\n\\tThanks, \\n\\tAni.\\n-- \\nTo get irritated is human, to stay cool, divine.\\n\",\n",
              " \"From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSubject: Re: harrassed at work, could use some prayers\\nOrganization: =CSE Dept., U.C. San Diego\\nLines: 63\\n\\n(Well, I'll email also, but this may apply to other people, so\\nI'll post also.)\\n\\n>I've been working at this company for eight years in various\\n>engineering jobs.  I'm female.  Yesterday I counted and realized that\\n>on seven different occasions I've been sexually harrassed at this\\n>company.\\n\\n>I dreaded coming back to work today.  What if my boss comes in to ask\\n>me some kind of question...\\n\\nYour boss should be the person bring these problems to.  If he/she\\ndoes not seem to take any action, keep going up higher and higher.\\nSexual harrassment does not need to be tolerated, and it can be an\\nenormous emotional support to discuss this with someone and know that\\nthey are trying to do something about it.  If you feel you can not\\ndiscuss this with your boss, perhaps your company has a personnel\\ndepartment that can work for you while preserving your privacy.  Most\\ncompanies will want to deal with this problem because constant anxiety\\ndoes seriously affect how effectively employees do their jobs.\\n\\nIt is unclear from your letter if you have done this or not.  It is\\nnot inconceivable that management remains ignorant of employee\\nproblems/strife even after eight years (it's a miracle if they do\\nnotice).  Perhaps your manager did not bring to the attention of\\nhigher ups?  If the company indeed does seem to want to ignore the\\nentire problem, there may be a state agency willing to fight with\\nyou.  (check with a lawyer, a women's resource center, etc to find out)\\n\\nYou may also want to discuss this with your paster, priest, husband,\\netc.  That is, someone you know will not be judgemental and that is\\nsupportive, comforting, etc.  This will bring a lot of healing.\\n\\n>So I returned at 11:25, only to find that ever single\\n>person had already left for lunch.  They left at 11:15 or so.  No one\\n>could be bothered to call me at the other building, even though my\\n>number was posted.\\n\\nThis happens to a lot of people.  Honest.  I believe it may seem\\nto be due to gross insensitivity because of the feelings you are\\ngoing through.  People in offices tend to be more insensitive while\\nworking than they normally are (maybe it's the hustle or stress or...)\\nI've had this happen to me a lot, often because they didn't realize\\nmy car was broken, etc.  Then they will come back and wonder why I\\ndidn't want to go (this would tend to make me stop being angry at\\nbeing ignored and make me laugh).  Once, we went off without our\\nboss, who was paying for the lunch :-)\\n\\n>For this\\n>reason I hope good Mr. Moderator allows me this latest indulgence.\\n\\nWell, if you can't turn to the computer for support, what would\\nwe do?  (signs of the computer age :-)\\n\\nIn closing, please don't let the hateful actions of a single person\\nharm you.  They are doing it because they are still the playground\\nbully and enjoy seeing the hurt they cause.  And you should not\\naccept the opinions of an imbecile that you are worthless - much\\nwiser people hold you in great esteem.\\n-- \\nDarin Johnson\\ndjohnson@ucsd.edu\\n  - Luxury!  In MY day, we had to make do with 5 bytes of swap...\\n\",\n",
              " 'From: s0612596@let.rug.nl (M.M. Zwart)\\nSubject: catholic church poland\\nOrganization: Faculteit der Letteren, Rijksuniversiteit Groningen, NL\\nLines: 10\\n\\nHello,\\n\\nI\\'m writing a paper on the role of the catholic church in Poland after 1989. \\nCan anyone tell me more about this, or fill me in on recent books/articles(\\nin english, german or french). Most important for me is the role of the \\nchurch concerning the abortion-law, religious education at schools,\\nbirth-control and the relation church-state(government). Thanx,\\n\\n                                                 Masja,\\n\"M.M.Zwart\"<s0612596@let.rug.nl>\\n',\n",
              " 'From: stanly@grok11.columbiasc.ncr.com (stanly)\\nSubject: Re: Elder Brother\\nOrganization: NCR Corp., Columbia SC\\nLines: 15\\n\\nIn article <Apr.8.00.57.41.1993.28246@athos.rutgers.edu> REXLEX@fnal.gov writes:\\n>In article <Apr.7.01.56.56.1993.22824@athos.rutgers.edu> shrum@hpfcso.fc.hp.com\\n>Matt. 22:9-14 \\'Go therefore to the main highways, and as many as you find\\n>there, invite to the wedding feast.\\'...\\n\\n>hmmmmmm.  Sounds like your theology and Christ\\'s are at odds. Which one am I \\n>to believe?\\n\\nIn this parable, Jesus tells the parable of the wedding feast. \"The kingdom\\nof heaven is like unto a certain king which made a marriage for his son\".\\nSo the wedding clothes were customary,  and \"given\" to those who \"chose\" to\\nattend.  This man \"refused\" to wear the clothes.  The wedding clothes are\\nequalivant to the \"clothes of righteousness\".  When Jesus died for our sins,\\nthose \"clothes\" were then provided.  Like that man, it is our decision to\\nput the clothes on.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eLf7tArQtXt",
        "colab_type": "code",
        "outputId": "91fcc190-caef-4b79-f564-990619fecbfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twenty_test.target"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U6BldLgQxgv",
        "colab_type": "code",
        "outputId": "d2b3900b-842b-4707-a336-1d5502950dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twenty_test.target_names"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se1_1ortQ0zs",
        "colab_type": "code",
        "outputId": "f1ceceb4-4c06-4b2c-bfb9-99f3505b1b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "twenty_test.data[0:5]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"From: brian@ucsd.edu (Brian Kantor)\\nSubject: Re: HELP for Kidney Stones ..............\\nOrganization: The Avant-Garde of the Now, Ltd.\\nLines: 12\\nNNTP-Posting-Host: ucsd.edu\\n\\nAs I recall from my bout with kidney stones, there isn't any\\nmedication that can do anything about them except relieve the pain.\\n\\nEither they pass, or they have to be broken up with sound, or they have\\nto be extracted surgically.\\n\\nWhen I was in, the X-ray tech happened to mention that she'd had kidney\\nstones and children, and the childbirth hurt less.\\n\\nDemerol worked, although I nearly got arrested on my way home when I barfed\\nall over the police car parked just outside the ER.\\n\\t- Brian\\n\",\n",
              " 'From: rind@enterprise.bih.harvard.edu (David Rind)\\nSubject: Re: Candida(yeast) Bloom, Fact or Fiction\\nOrganization: Beth Israel Hospital, Harvard Medical School, Boston Mass., USA\\nLines: 37\\nNNTP-Posting-Host: enterprise.bih.harvard.edu\\n\\nIn article <1993Apr26.103242.1@vms.ocom.okstate.edu>\\n banschbach@vms.ocom.okstate.edu writes:\\n>are in a different class.  The big question seems to be is it reasonable to \\n>use them in patients with GI distress or sinus problems that *could* be due \\n>to candida blooms following the use of broad-spectrum antibiotics?\\n\\nI guess I\\'m still not clear on what the term \"candida bloom\" means,\\nbut certainly it is well known that thrush (superficial candidal\\ninfections on mucous membranes) can occur after antibiotic use.\\nThis has nothing to do with systemic yeast syndrome, the \"quack\"\\ndiagnosis that has been being discussed.\\n\\n\\n>found in the sinus mucus membranes than is candida.  Women have been known \\n>for a very long time to suffer from candida blooms in the vagina and a \\n>women is lucky to find a physician who is willing to treat the cause and \\n>not give give her advise to use the OTC anti-fungal creams.\\n\\nLucky how?  Since a recent article (randomized controlled trial) of\\noral yogurt on reducing vaginal candidiasis, I\\'ve mentioned to a \\nnumber of patients with frequent vaginal yeast infections that they\\ncould try eating 6 ounces of yogurt daily.  It turns out most would\\nrather just use anti-fungal creams when they get yeast infections.\\n\\n>yogurt dangerous).  If this were a standard part of medical practice, as \\n>Gordon R. says it is, then the incidence of GI distress and vaginal yeast \\n>infections should decline.\\n\\nAgain, this just isn\\'t what the systemic yeast syndrome is about, and\\nhas nothing to do with the quack therapies that were being discussed.\\nThere is some evidence that attempts to reinoculate the GI tract with\\nbacteria after antibiotic therapy don\\'t seem to be very helpful in\\nreducing diarrhea, but I don\\'t think anyone would view this as a\\nquack therapy.\\n-- \\nDavid Rind\\nrind@enterprise.bih.harvard.edu\\n',\n",
              " 'From: adwright@iastate.edu ()\\nSubject: Re: centi- and milli- pedes\\nOrganization: Iowa State University, Ames IA\\nLines: 37\\n\\nIn <1993Apr29.112642.1@vms.ocom.okstate.edu> chorley@vms.ocom.okstate.edu writes:\\n\\n>In article <35004@castle.ed.ac.uk>, gtclark@festival.ed.ac.uk (G T Clark) writes:\\n>> msnyder@nmt.edu (Rebecca Snyder) writes:\\n>> \\n>>>Does anyone know how posionous centipedes and millipedes are? If someone\\n>>>was bitten, how soon would medical treatment be needed, and what would\\n>>>be liable to happen to the person?\\n>> \\n>>>(Just for clarification - I have NOT been bitten by one of these,  but my\\n>>>house seems to be infested, and I want to know \\'just in case\\'.)\\n>> \\n>>>Rebecca\\n>> \\n>> \\n>> \\tMillipedes, I understand, are vegetarian, and therefore almost\\n>> certainly will not bite and are not poisonous. Centipedes are\\n>> carnivorous, and although I don\\'t have any absolute knowledge on this, I\\n>> would tend to think that you\\'re in no danger from anything but a\\n>> concerted assault by several million of them.\\n>> \\n>> \\t\\t\\tG.\\n>Not sure of this but I think some millipedes cause a toxic reaction (sting?\\n>So I would not assume that they are not dangerous merely on the basis of \\n>vegetarianism, after all wasps are vegetarian too.\\n>dnc.\\n\\nAs a child i can remember picking up a centipede and getting a rather painful \\nsting, but it quickly subsided. Much less painful compared to a bee sting. \\nCentipedes have a poison claw (one of the front feet) to stun their prey, but\\nin my single experience it did not have a lot of \"bite\" to it.\\n\\nA.\\n\\n\\n\\n\\n',\n",
              " \"From: livesey@solntze.wpd.sgi.com (Jon Livesey)\\nSubject: Re: free moral agency\\nOrganization: sgi\\nLines: 26\\nDistribution: world\\nNNTP-Posting-Host: solntze.wpd.sgi.com\\n\\nIn article <C5uuL0.n1C@darkside.osrhe.uoknor.edu>, bil@okcforum.osrhe.edu (Bill Conner) writes:\\n|> \\n|> Many of the atheists posting here argue against their own parody of\\n|> religion; they create some ridiculous caricature of a religion and\\n|> then attack the believers within that religion and the religion itself\\n|> as ridiculous. By their own devices, they establish a new religion, a\\n|> mythology.\\n\\nYou mean Bobby Mozumder is a myth?    We wondered about that.\\n\\n|> The point of course, is to erect an easy target and deflect the\\n|> disputants away from the real issue - atheism. The fictional Christian\\n|> or Moslem or Jew who is supposed to believe the distorted\\n|> representation of their beliefs presented here, is therefore made to\\n|> seem a fool and his/her arguments can thereby be made to appear\\n|> ludicrous. The mythology is the misrepresentations of religion used\\n|> here as fact.\\n\\nYou mean Bobby Mozumder didn't really post here?   We wondered\\nabout that, too.\\n\\nSo, Mr Conner.   Is Bobby Mozumder a myth, a performing artist, \\na real Moslem. a crackpot, a provocateur?    You know everything\\nand read all minds: why don't you tell us?\\n\\njon.\\n\",\n",
              " 'From: jhpb@sarto.budd-lake.nj.us (Joseph H. Buehler)\\nSubject: the ancient canon of the Roman rite\\nOrganization: none\\nLines: 132\\n\\nThe following is a juxtaposition of part of an ancient text known as\\n\"de Sacramentis\", usually attributed to St. Ambrose of Milan, and the\\ncanon of the traditional Catholic Mass of the Roman rite.  The\\nconclusion from this comparison is that the central part of the\\ntraditional Roman canon was already fairly well in place by sometime\\nin the late 4th century.\\n\\nTaken from \"The Mass of the Western Rites\", by the Right Reverend Dom\\nFernand Cabrol, Abbot of Farnborough, 1934, without permission.\\nExcerpted from Chapter VI: THE MASS AT ROME, FROM THE FIFTH TO THE\\nSEVENTH CENTURIES.  The paragraph at the end is from the book, not me.\\n\\nSorry about the long lines.\\n\\nJoe Buehler\\n\\n-----\\n\\nTEXT OF DE SACRAMENTIS          ROMAN CANON                     ROMAN CANON\\n(about 400 AD)                  (1962 AD)                       (English translation)\\n\\n                                Te igitur ...                   (omitted here)\\n                                Memento Domine ...\\n                                Communicantes ...\\n                                Hanc igitur oblationem ...\\n\\nFac nobis (inquit sacerdos),    Quam oblationem tu Deus, in     Do thou, O God, deign to\\nhanc oblationem ascriptam,      omnibus, quaesumus,             bless what we offer, and\\nratam, rationabilem,            benedictam, adscriptam,         make it approved,\\nacceptabilem, quod figura       ratam, rationabilem,            effective, right, and\\nest corporis et sanguinis       acceptabilemque facere          wholly pleasing in every\\nJesu Christi.                   digneris: ut nobis corpus et    way, that it may become\\n                                sanguis fiat dilectissimi       for our good, the Body\\n                                Filii tui Domini nostri Jesu    and Blood of Thy dearly\\n                                Christi.                        beloved Son, Jesus Christ\\n                                                                our Lord.\\n\\nQui pridie quam pateretur,      Qui pridie quam pateretur,      Who, the day before He\\nin sanctis manibus suis         accepit panem in sanctas ac     suffered, took bread into\\naccepit panem, respexit in      venerabiles manus suas: et      His holy and venerable\\ncaelum ad te, sancte Pater      elevatis oculis in ccelum,      hands, and having raised\\nomnipotens, aeterne Deus,       ad Te Deum Patrem suum          His eyes to Heaven, unto\\nGratias agens, benedixit,       omnipotentem, tibi gratias      Thee, O God, His Almighty\\nfregit, fractum quae            agens, benedixit, fregit,       Father, giving thanks to\\napostolis suis et discipulis    deditque discipulis suis        Thee, He blessed it, broke\\nsuis tradidit dicens:           dicens: accipite et             it, and gave it to His\\naccipite et edite ex hoc        manducate ex hoc omnes: hoc     disciples, saying: Take ye\\nomnes: hoc est enim corpus      est enim corpus meum.           all and eat of this:\\nmeum, quod pro multis                                           For this is my Body.\\nconfringetur.\\n\\nSimiliter etiam calicem         Simili modo postquam            In like manner, when the\\npostquam caenatum est,          caenatum est, accipiens et      supper was done, taking\\npridie quam pateretur,          hunc praeclarum calicem in      also this goodly chalice\\naccepit, respexit in            sanctas ac venerabiles manus    into His holy and\\ncaelum ad te, sancte pater      suas item tibi gratias          venerable hands, again\\nomnipotens, aeterne Deus,       agens, benedixit deditque       giving thanks to Thee,\\ngratias agens, benedixit,       discipulis suis, dicens:        He blessed it, and gave it\\napostolis suis et discipulis    accipite et bibite ex eo        to His disciples, saying:\\nsuis tradidit, dicens:          omnes: Hic est enim calix       Take ye all, and drink of\\naccipite et bibite ex hoc       sanguinis mei, novi et          this: For this is the\\nomnes: hic est enim sanguis     aeterni testamenti:             Chalice of my Blood of the\\nmeus.                           mysterium fidei; qui pro        new and eternal covenant;\\n                                vobis et pro multis             the mystery of faith,\\n                                effundetur in remissionem       which shall be shed for\\n                                peccatorum.                     you and for many unto the\\n                                                                forgiveness of sins.\\n\\n                                Haec quotiescumque feceritis    As often as you shall do\\n                                in mei memoriam facietis.       these things, in memory of\\n                                                                Me shall you do them.\\n\\nErgo memores gloriosissimae     Unde et memores, Domine, nos    Mindful, therefore, O\\nejus passionis et ab inferis    servi tui, sed et plebs tua     Lord, not only of the\\nresurrectionis, in caelum       sancta, ejusdem Christi         blessed Passion of the\\nascensionis, offerimus tibi     Filii tui Domini nostri, tam    same Christ, Thy Son, our\\nhanc immaculatam hostiam,       beatae passionis necnon et      Lord, but also of His\\nhunc panem sanctum et           ab inferis resurrectionis,      resurrection from the\\ncalicem vitae aeternae;         sed et in caelos gloriosae      dead, and finally His\\n                                ascensionis: offerimus          glorious ascension into\\n                                praeclarae majestati tuae de    Heaven, we, Thy ministers,\\n                                tuis donis ac datis, hostiam    as also Thy holy people,\\n                                puram, hostiam sanctam,         offer unto Thy supreme\\n                                hostiam immaculatam, Panem      majesty, of the gifts\\n                                sanctum vitae aeternae, et      bestowed upon us, the\\n                                Calicem salutis perpetuae.      pure Victim, the holy\\n                                                                Victim, the all-perfect\\n                                                                Victim: the holy Bread of\\n                                                                life eternal and the\\n                                                                Chalice of unending\\n                                                                salvation.\\n\\net petimus et precamur, ut      Supra quae propitio ac          And this do Thou deign to\\nhanc oblationem suscipias in    sereno vultu respicere          regard with gracious and\\nsublimi altari tuo per manus    digneris: et accepta habere,    kindly attention and hold\\nangelorum tuorum sicut          sicuti accepta, habere          acceptable, as Thou didst\\nsuscipere dignatus es munera    dignatus es munera pueri tui    deign to accept the\\npueri tui justi Abel et         justi Abel, et sacrificium      offerings of Abel, Thy\\nsacrificium patriarchae         patriarchae nostri Abrahae,     just servant, and the\\nnostri Abrahae et quod tibi     et quod tibi obtulit summus     sacrifice of Abraham our\\nobtulit summus sacerdos         sacerdos tuus Melchisedech      patriarch, and that which\\nMelchisedech.                   sanctum sacrificium,            Thy chief priest\\n                                immaculatam hostiam.            Melchisedech offered unto\\n                                                                Thee, a holy sacrifice and\\n                                                                a spotless victim.\\n\\n                                Supplices te rogamus,           Most humbly we implore\\n                                omnipotens Deus: jube haec      Thee, almighty God, bid\\n                                perferri per manus sancti       these offerings to be\\n                                Angeli tui in sublime altare    brought by the hands of\\n                                tuum in conspectu divinae       Thy holy angel unto Thy\\n                                majestatis tuae: etc.           altar above; before the\\n                                                                face of Thy Divine\\n                                                                Majesty; etc.\\n\\nThere is no doubt that we have here two editions of the same\\ntext; and as that of De Sacramentis is localised in Upper Italy\\nand dated about the year 400, it is the most ancient witness we\\npossess as to the principal parts of the Roman canon, which only\\nappear in the Sacramentaries some time after the seventh\\ncentury. The question as to whether the Roman canon is not older\\neven than that of De Sacramentis is discussed by\\nliturgiologists.  Mgr. Batiffol is of this opinion, but we, on\\nthe contrary, think that the former bears traces of closer\\ncomposition, of a more carefully guarded orthodoxy, and that\\nconsequently it is a text corrected from De Sacramentis. We\\nshall see, in studying the list of names in the Memento of the\\nliving and that of the dead, that Mgr. Batiffol argues with good\\nreason that he can date these fragments from the pontificate of\\nSymmachus (498-514). We thus have the state of the Roman Mass,\\nor at least of the chief parts of the canon, at the beginning of\\nthe fourth century.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTz4EaN_1WGc",
        "colab_type": "text"
      },
      "source": [
        "### 9.  Now with dependent and independent data available for both train and test datasets, using TfidfVectorizer fit and transform the training data and test data and get the tfidf features for both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5G477f81C0Z",
        "colab_type": "code",
        "outputId": "41cbc9c3-6ccd-4a93-b38b-22940c6415ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Creating the bag of words...\")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the \"TfidfVectorizer\" object, which is scikit-learn's\n",
        "# bag of words tool.  \n",
        "vect = TfidfVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None,   \\\n",
        "                             max_features = 10000) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the bag of words...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wku4STR1SjpK",
        "colab_type": "code",
        "outputId": "7b487463-5d9a-4b94-e425-61277d36dfd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blDsjmOESrSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_train_df = pd.DataFrame(twenty_train.data,columns=['tweet_text'])\n",
        "tweets_test_df = pd.DataFrame(twenty_test.data,columns=['tweet_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7LyozIGS7XJ",
        "colab_type": "code",
        "outputId": "c51474b8-4f9b-467e-fac1-bc3e4533ee38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tweets_train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: sd345@city.ac.uk (Michael Collier)\\nSubj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: stanly@grok11.columbiasc.ncr.com (stanly...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text\n",
              "0  From: sd345@city.ac.uk (Michael Collier)\\nSubj...\n",
              "1  From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...\n",
              "2  From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...\n",
              "3  From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...\n",
              "4  From: stanly@grok11.columbiasc.ncr.com (stanly..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn1HY0JvS_c-",
        "colab_type": "code",
        "outputId": "521fbb57-e3f7-40e6-afdd-b58e0346b21c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tweets_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: brian@ucsd.edu (Brian Kantor)\\nSubject: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: rind@enterprise.bih.harvard.edu (David R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: adwright@iastate.edu ()\\nSubject: Re: ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text\n",
              "0  From: brian@ucsd.edu (Brian Kantor)\\nSubject: ...\n",
              "1  From: rind@enterprise.bih.harvard.edu (David R...\n",
              "2  From: adwright@iastate.edu ()\\nSubject: Re: ce...\n",
              "3  From: livesey@solntze.wpd.sgi.com (Jon Livesey...\n",
              "4  From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10sdr0ovTIvP",
        "colab_type": "text"
      },
      "source": [
        "**Prepare the Train Data by removing unwanted characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1jr2FGBTHIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1 to remove HTML and other Tags\n",
        "tweets_train_df['tweet_text'] = [BeautifulSoup(text).get_text() for text in tweets_train_df['tweet_text'] ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGr5PZ0BTjEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2 to remove all non english characters and also remove stop words, converting all words to lower case\n",
        "for i, row in tweets_train_df.iterrows():\n",
        "  tweets_train_df['tweet_text'][i] = re.sub(\"[^0-9a-zA-Z]\",\" \",tweets_train_df['tweet_text'][i] )\n",
        "  words = tweets_train_df['tweet_text'][i].lower().split()                             \n",
        "  stops = set(stopwords.words(\"english\"))                  \n",
        "  meaningful_words = [w for w in words if not w in stops]   \n",
        "  tweets_train_df['tweet_text'][i] = \" \".join( meaningful_words )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL8w4uynTwc-",
        "colab_type": "code",
        "outputId": "7927d323-d766-421b-9dc3-595b6a0ee60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(tweets_train_df[\"tweet_text\"].iloc[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sd345 city ac uk michael collier subject converting images hp laserjet iii nntp posting host hampton organization city university lines 14 anyone know good way standard pc application pd utility convert tif img tga files laserjet iii format would also like converting hpgl hp plotter files please email response correct group thanks advance michael michael collier programmer computer unit email p collier uk ac city city university tel 071 477 8000 x3769 london fax 071 477 8565 ec1v 0hb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UcOuvLEUGqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_train_tfidf_df = vect.fit_transform(tweets_train_df['tweet_text'])\n",
        "tweets_train_tfidf_df = tweets_train_tfidf_df.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLm3op7DUglp",
        "colab_type": "code",
        "outputId": "c034766a-bd02-4169-eb09-c6cd3075d3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = vect.get_feature_names()\n",
        "len(vocab)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N-P6D8UVF56",
        "colab_type": "text"
      },
      "source": [
        "**Prepare the Test Data by removing unwanted characters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1rVXXYLVLK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1 to remove HTML and other Tags\n",
        "tweets_test_df['tweet_text'] = [BeautifulSoup(text).get_text() for text in tweets_test_df['tweet_text'] ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xce1JAmuVVms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2 to remove all non english characters and also remove stop words, converting all words to lower case\n",
        "for i, row in tweets_test_df.iterrows():\n",
        "  tweets_test_df['tweet_text'][i] = re.sub(\"[^0-9a-zA-Z]\",\" \",tweets_test_df['tweet_text'][i] )\n",
        "  words = tweets_test_df['tweet_text'][i].lower().split()                             \n",
        "  stops = set(stopwords.words(\"english\"))                  \n",
        "  meaningful_words = [w for w in words if not w in stops]   \n",
        "  tweets_test_df['tweet_text'][i] = \" \".join( meaningful_words )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNVN36xvVgyr",
        "colab_type": "code",
        "outputId": "083e0494-45da-429f-f27d-23318d0ccbba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(tweets_test_df[\"tweet_text\"].iloc[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "brian ucsd edu brian kantor subject help kidney stones organization avant garde ltd lines 12 nntp posting host ucsd edu recall bout kidney stones medication anything except relieve pain either pass broken sound extracted surgically x ray tech happened mention kidney stones children childbirth hurt less demerol worked although nearly got arrested way home barfed police car parked outside er brian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovv3Dy68Vpqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_test_tfidf_df = vect.fit_transform(tweets_test_df['tweet_text'])\n",
        "tweets_test_tfidf_df = tweets_test_tfidf_df.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg27skzfV2FH",
        "colab_type": "code",
        "outputId": "61b86595-25b1-4021-8bcb-6e0eee365e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = vect.get_feature_names()\n",
        "len(vocab)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp_fDINJ1t4L",
        "colab_type": "text"
      },
      "source": [
        "### 10. Use logisticRegression with tfidf features as input and targets as output and train the model and report the train and test accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWYU5ruNOlH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tweets_train_tfidf_df\n",
        "y_train = twenty_train.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOi-mbkTWWl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = tweets_test_tfidf_df\n",
        "y_test = twenty_test.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaSHIxcHWc67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zegd4D26Wh_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_LR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW7bm7qEWnSC",
        "colab_type": "code",
        "outputId": "449bdb07-03ab-4658-fbd1-3e550327886d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_LR.score(X_test, y_test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2822902796271638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY6BndGHWuDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}